### 一、CLIP

单塔结构

##### 1. [CVPR 2022] Grounded Language-Image Pre-training 

GLIP

https://arxiv.org/abs/2112.03857  

和localization相关，对于后续工作有一定帮助

##### 2. [NeurIPS 2022] Unifying Localization and Vision-Language Understanding

GLIPv2

https://arxiv.org/abs/2206.05836

##### 3. [NeurIPS 2022] Flamingo: a Visual Language Model for Few-Shot Learning 

https://arxiv.org/abs/2204.14198

### 二、BLIP

双塔结构

ViLT (2021) 多模态大模型的encoder-decoder架构（单塔或双塔）

##### 1. [ICML 2022]BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation

##### 2. [CVPR 2023]BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models

### 三、2023最新论文

##### 1. MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models

##### 2. Visual Instruction Tuning (LLaVA)

##### 3. mPLUG-Owl : Modularization Empowers Large Language Models with Multimodality

以上三个工作都有对应的v2版本。对于v2版本看看相应论文在数据、模型上的一些改变

多模态大模型综述：
相关工作，https://arxiv.org/pdf/2306.13549.pdf （https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models）
幻觉相关（最近比较火，在了解多模态大模型后关注一下，还没有一个比较好和完整的survey，可以根据hallucination进行检索一些文章）

### 四、下个工作相关的最新研究

##### 1. Localized Symbolic Knowledge Distillation for Visual Commonsense Models （NeurIPS 2023）

##### 2. ShareGPT4V: Improving Large Multi-Modal Models with Better Captions （2023.11）
